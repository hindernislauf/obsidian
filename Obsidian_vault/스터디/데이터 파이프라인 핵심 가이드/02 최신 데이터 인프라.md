# 1. 데이터 소스의 다양성

- 대부분 조직에는 여러 개의 데이터 소스 존재
  → 소유 중인 데이터 소스를 이용한 분석 작업 수행 가능

### 소스 시스템 소유권

 - 데이터 소스
	 - 조직이 구축하고 소유한 소스 시스템
		 - e.g. 자사 앱에서 생성되는 데이터를 PostgresSQL 데이터베이스에 저장
	 - 타사 도구 · 공급업체
		 - e.g. 타사 웹 분석 도구(Google Analytics)를 사용한 웹 사이트 사용 추적
	 - 데이터 파이프라인
		 - 두 소스 모두에서 데이터를 수집하면서 시작 
		   → 데이터 분석으로 종료
		- 데이터 수집: 한 소스에서 데이터를 추출하여 다른 소스로 로드하는 것을 의미
		![|400](https://i.imgur.com/pjUKNkq.png)

- 소스 시스템 소유권의 중요성
	1. 타사 데이터 소스의 데이터에 액세스할 때, 액세스 방법의 제한 가능성
		- 예) 대다수 솔루션 공급업체: REST API 제공 / SQL 데이터베이스 미제공
		- 액세스 가능한 데이터와 세부 수준을 사용자 환경에 맞추기 어려움
	2. 내부 구축 시스템의 데이터에 액세스할 때, 자유로운 액세스 방법 제공 가능
		- 사용자 필요에 맞추어 데이터 형태 정의 가능
		  → 분석 팀에 더 많은 분석 기회 제공 가능
		- 시스템 구축 시, 데이터 수집을 고려한 설계 여부는 별개의 문제임
			- 예) 데이터 수집이 의도하지 않은 시스템 부하 야기 문제, 데이터의 점진적(incremental) 로드 가능 여부 등 다양한 과제 발생
			- 제한적인 리소스로 소스 시스템 소유 엔지니어 팀과 협력이 어려울 수 있음

  ![|400](https://i.imgur.com/pjUKNkq.png)

### 수집 인터페이스 및 데이터 구조

- 데이터 엔지니어가 새로운 데이터 수집 구축 시, 소스 데이터를 얻는 방법 · 형식을 알아야 함
1. 데이터 인터페이스
	- 애플리케이션 뒤에 위치한 데이터베이스
		- e.g. Postgres, MySQL 등 backend database
	- 시스템 상단의 추상화 계층(예: REST API)
	- 스트림 처리 플랫폼(예: Apache Kafka)
	- Log, CSV(Comma Separated Value), 기타 플랫 파일이 저장되는 
	  NFS(Network File System) 또는 Cloud Storage Bucket
	- 데이터 웨어하우스 / 데이터 레이크
	- HDFS / HBase 데이터베이스의 데이터
2. 데이터 구조
	- REST API - JSON(JavaScript Object Notation)
	- MySQL DB의 잘 구성된 데이터
	- MySQL DB 테이블의 column 내 JSON
	- 반정형화된 로그 데이터
	- CSV, FWF(Fixed Width File, 고정 폭 형식), 기타 플랫 파일 형식
	- 플랫 파일 - JSON
	- Kafka 스트림 출력
- 각 인터페이스, 데이터 구조
  → 각각의 도전 과제와 기회 존재
	- 잘 구성된 데이터
		- 작업하기 가장 쉬운 편 / 일반적으로 애플리케이션 · 웹 사이트를 위해 정형화
		- 파이프라인 상 클렌징, 변환 작업 등 추가 단계 필요 가능성 존재
	- 반정형 데이터(JSON)
		- 장점: 속성-값 구조, 객체의 중첩(nesting) 구조
		- 단점: 데이터세트 내 데이터 구조의 동일성 보장 불가 / 데이터의 유연성이 커지면 필요 데이터 처리 방법도 증가
	- 비정형 데이터
		- 일부 분석 작업에 흔히 사용(예: NLP, CV, 웹 크롤링 등)
### 데이터 사이즈

- 데이터 사이즈와 가치는 비례하지 않음
- 파이프라인의 각 단계 설계 시, 데이터 사이즈 고려 필요
### 데이터 클렌징 작업과 유효성 검사

- 소스 데이터의 한계와 결함을 이해하고 파이프라인의 적절한 부분에서 해결하는 것이 중요
- '지저분한 데이터' 공통적 특성
	- 중복되거나 모호한 레코드
	- 고립된 레코드
	- 불완전하거나 누락된 레코드
	- 텍스트 인코딩 오류
	- 일치하지 않는 형식(예: 대시(-)가 있는 전화번호와 없는 전화번호)
	- 레이블이 잘못되었거나 레이블이 지정되지 않은 데이터
- 데이터 클렌징과 유효성을 보장하기 위한 주요 특성과 접근 방식
	- 최악을 가정하고 최상을 기대하라
		- 입력 데이터세트에 수많은 유효성 및 일관성 문제가 있지만,
		  깨끗한 출력을 위해 데이터를 식별하고 정리하는 파이프라인을 구축한다고 가정
	- 가장 적합한 시스템에서 데이터를 정리하고 검증하라
		- 때로는 데이터를 원본 그대로 데이터 레이크에 로드 후 나중에 파이프라인에서 정형화 및 정리하는 방식이 좋을 수 있음(ETL → ELT)
		- 데이터 클렌징과 검증 프로세스 → 올바른 작업에 올바른 도구 사용
	- 자주 검증하라
		- 파이프라인 종료 단계에서 데이터 검증 시, 문제 발생 단계 파악이 어려움

### 소스 시스템의 지연 시간 및 대역폭

- 파이프라인의 데이터 추출 단계는 소스 시스템의 소유자가 불만이 생기게 할 수 있음
- 불만 요인
	- API 속도 제한
	- 연결 시간 초과
	- 느린 다운로드
	- 시스템에 대한 부담

---
# 2. 클라우드 데이터 웨어하우스 및 데이터 레이크

**[분석 및 데이터 웨어하우징 환경 변화 요소 3가지]**
- 주요 클라우드 공급업체(Amazon, Google, Microsoft)의 등장과 관련됨
1. 클라우드 컴퓨팅 서비스로의 전환
	- 클라우드에서 데이터 파이프라인, 데이터 레이크, 웨어하우스 및 분석 처리 구축 및 배포가 쉬워짐
	  → 더 이상 IT부서와 대규모 초기 비용에 대한 예산을 기다릴 필요가 없어짐
	  → 클라우드 공급업체에서 관리해주는 관리 서비스가 주류가 됨
2. 지속적인 클라우드 내 스토리지 비용 감소
3. Amazon RedShift, Snowflake, Google BigQuery와 같은 확장성 뛰어난 열 기반 데이터베이스의 등장

- 이러한 변화는 데이터 레이크의 개념을 도입하게 됨
- **데이터 웨어하우스**
	- 사용자가 원하는 질문에 대답할 수 있는 데이터 분석 활동을 지원하기 위해 서로 다른 시스템의 데이터가 모델링되어 저장되는 데이터 베이스
	- 리포팅 및 분석 쿼리를 위해 정형화되고 최적화됨
- **데이터 레이크**
	- 데이터가 저장되지만 데이터 웨어하우스처럼 데이터 구조나 쿼리 최적화가 필요 없음
	- 정형화된 데이터를 쿼리하는 데 최적화되지 않았지만 리포팅 및 분석을 위해 데이터 저장 가능

| [구분] | [데이터 웨어하우스]                                                                                     | [데이터 레이크]                                                                                                              |
| ---- | ----------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| 목적   | 분석에 최적화된 데이터 저장소                                                                                | 다양한 형식의 데이터를 대량으로 저장                                                                                                   |
| 데이터  | 주로 정해진 형식이 있는 **정형화된 데이터**<br>(Excel의 표 형식 데이터)                                                 | **정형, 반정형, 비정형 데이터**를 모두 저장<br>(동영상, 이미지, 로그파일 등)                                                                      |
| 사용자  | 데이터 분석가, 비즈니스 인텔리전스팀                                                                            | 데이터 사이언티스트, 엔지니어, 분석가                                                                                                  |
| 특징   | - 데이터가 정리 및 구조화된 상태로 들어옴<br>- 복잡한 쿼리나 보고서를 쉽게 작성할 수 있도록 설계<br>- **많은 양의 데이터**를 오랫동안 보관하는 것에 최적화 | - 데이터를 **원래 형태로 저장**하며, **필요할 때 분석**<br>- 다양한 데이터 소스를 유연하게 다룸<br>- 데이터를 원본 그대로 저장하기 때문에 데이터를 <br>미리 구조화하거나 최적화할 필요가 없음 |
| 예시   | 고객 구매 기록을 분석하여 매출 보고서를 <br>만들어 향후 판매 전략을 수립할 때 사용                                               | 웹사이트의 사용자 활동 기록, 소셜 미디어에서 <br>수집한 텍스트 데이터, 서버 로그 등을 저장하여 필요시 분석                                                        |
- 비교
	- 데이터 정제 : 데이터웨어하우스는 데이터를 미리 정리하고, 정제된 상태로 저장하는 반면, 데이터레이크는 데이터를 원래 형태로 저장하여 나중에 필요에 따라 정제할 수 있음
	- 유연성 : 데이터레이크는 구조화된 데이터와 비구조화된 데이터를 모두 저장할 수 있는 반면, 데이터웨어하우스는 주로 구조화된 데이터를 다룸
	- 목적: 데이터웨어하우스는 주로 즉각적인 비즈니스 분석을 위해 사용되며, 데이터레이크는 대규모 데이터 분석과 머신러닝에 유용함


# 3. 데이터 수집 도구

- 데이터 팀은 데이터를 수집할 다양한 데이터 소스를 생각해야 함
	- 최신 데이터 인프라의 상용 및 오픈 소스 도구를 사용할 수 있음
	- 가장 일반적인 도구 및 프레임워크 : **Singer, Stitch, Fivetran**
	  (데이터 수집 및 통합 도구로, 다양한 데이터 소스에서 데이터를 수집하고 이를 데이터 웨어하우스나 데이터 레이크 등으로 이동시키는 작업을 자동화하는 데 사용됨)
- Tool이 보급되었지만 자체 프레임워크를 직접 개발하는 경우도 있음
	- 대부분 아래와 같은 사유들로 자체 코드 구축/개발
	  1) 비용
	  2) 직접 구축하는 것을 선호하는 분위기
	  3) 외부 공급업체 신뢰에 따른 법적/보안적 위험에 대한 우려
	- 따라서, 데이터 수집 도구에 대해 직접 구축하는 것과 구매하는 것을 비교해볼 필요가 있음
	- 이때 중요한 것은 '상용 제품의 가치를 어디에 두느냐'
		→ 데이터 엔지니어가 데이터를 파이프라인에 더 쉽게 수집할 수 있도록 지원하는 제품이 필요한 경우
		→ 데이터 엔지니어 외 데이터 분석가와 같은 사람이 직접 수집을 구축할 수 있도록 지원하는 제품이 필요한 경우 등
	- 데이터 팀은 데이터 수집 중 수행하는 변환 횟수를 제한하기 때문에 소스로부터 **데이터를 추출**하고 **대상에 로드**하는 두 가지 기능을 갖춘 수집도구를 사용함

# 4. 데이터 변환 및 모델링 도구

- 데이터 파이프라인 : 머신러닝, 분석 및 리포팅과 같은 새로운 목적을 위해 데이터를 변환하고 모델링하는 작업으로 구성됨
- **데이터 변환**
	- ETL 또는 ELT 프로세스에서 T(Transform)에 해당
		- ETL : Extract(데이터 추출), Transform(데이터 변환), Load(데이터 적재)
	- 간단한 작업 → 저장된 타임스탬프를 한 시간대에서 다른 시간대로 변환(특정 시간대로 통일)
	- 복잡한 작업 → 일부 비즈니스 로직을 통해서 집계되고 필터링된 여러 원본 열을 바탕으로 새 지표를 생성
		- (e.g.) 판매 데이터와 마케팅 비용 데이터를 결합하여 ROI(투자 수익률)라는 새로운 지표를 계산
		- 이 과정에서 데이터는 필터링되거나 집계되며, 새로운 열이나 지표가 생성될 수 있음
- **데이터 모델링**
	- 구체적인 변환 유형으로, 데이터 분석을 위해 데이터를 이해하고 최적화된 형식으로 정형화하고 정의함
	- 일반적으로 데이터 웨어하우스에서 하나 이상의 테이블로 표시됨

- 최신 데이터 인프라의 방법론 및 도구들
	- 일부 데이터 수집 도구는 어느 정도 수준의 데이터 변환 기능을 제공하지만, 해당 기능들은 매우 간단한 경우가 많음
	- (e.g.) 개인 식별 가능 정보(PII)를 보호하기 위해 개인의 전자메일 주소를 최종 목적지에 저장된 해시 값으로 변환하는 것이 좋을 수 있음
	  → 이러한 변환은 일반적으로 수집 프로세스 중에 수행됨
- 복잡한 데이터 변환 및 데이터 모델링을 위해서는 DBT와 같이 작업을 위해 특별히 설계된 도구와 프레임워크를 찾는 것이 바람직함
	- DBT : ELT중에서 T(Transform)을 위해 제작된 도구로, 외부 데이터 소스로부터 데이터를 추출하거나 적재하는 기능을 하는 게 아닌 이미 적재되어 있는 데이터를 조회하고 수정하는 데에 최적화된 도구
- 데이터 변환은 SQL 및 파이썬과 같은 DE 및 DA에게 익숙한 언어로 작성할 수 있음
- 분석 및 보고에 사용되는 데이터 모델은 일반적으로 SQL또는 GUI 사용자 인터페이스를 통해 정의 및 작성됨
	- SQL은 DE와 DA 모두에게 익숙한 접근성 높은 언어
	- DA는 데이터로 직접 작업하고 필요에 따라 모델 설계 최적화 가능
	- 거의 모든 조직에서 사용되므로 신입사원에게도 익숙할 정도의 낮은 진입장벽 제공
	- 대부분의 경우 GUI보다는 **SQL에서 데이터 모델 구축을 지원하는 변환 프레임워크를 선택**하는 것이 바람직함
	  → 훨씬 더 많은 사용자 정의가 가능하고 개발 프로세스에 처음부터 끝까지 관여할 수 있음

# 5. 워크플로 오케스트레이션 플랫폼

- 조직의 데이터 파이프라인의 복잡성과 수가 증가함에 따라 데이터 인프라에 '워크플로 오케스트레이션 플랫폼'을 도입하는 것이 중요
	- 이는 파이프라인에서 작업의 스케줄링 및 흐름을 관리
	- *워크플로 관리 시스템(WMS)* 또는 *오케스트레이션 플랫폼* 또는 *오케스트레이션 프레임워크*라고도 함
	- 종류 : Apache Airflow, Luigi, AWS Glue, Kubeflow Pipeline(Docker 컨테이너에 구축된 머신러닝 워크플로)

### 방향성 비순환 그래프(DAGs)

- 대부분의 최신 오케스트레이션 프레임워크는 **파이프라인에서 작업의 흐름과 종속성을 그래프로** 나타내지만, 파이프라인 그래프에는 특정 제약 조건이 있음
	1. 파이프라인 단계는 항상 **방향성**을 가진다.
		- 하나의 작업 또는 여러 개의 작업으로 시작하고 특정 작업으로 끝남
		- 실행 경로와 순서를 보장하기 위해 방향성 필요
		- 모든 종속 작업이 완료되어야만 다음 작업이 실행됨
	2. 파이프라인 그래프는 **비순환**(acyclic) 그래프여야 한다.
		- 이전에 완료된 작업을 다음 작업으로 가리킬 수 없음
		- 작업은 돌아갈 수 없기 때문에 순환 불가, 다음 작업으로만 갈 수 있음

![300](https://i.imgur.com/2EtiJiw.png)
- [그림] 네 가지 작업이 있는 DAG
	- 작업_A가 완료되면 작업_B와 작업_C가 실행되고, 둘 다 완료되면 작업_D가 실행됨
	- 작업_D가 완료되면 파이프라인도 함께 완료됨
- DAG : 작업들의 집합을 나타내며 작업이 수행해야 하는 실제 내용은 DAG에 저장되어 있지 않음

![450](https://i.imgur.com/KUITbYI.png)
- [그림] 세 가지 작업이 있는 DAG
	- *SQL DB에서 데이터를 추출*
	  → RDB에서 데이터를 쿼리하고 결과를 CSV파일에 저장하는 SQL 스크립트를 실행한다.
	- *파이썬 스크립트를 사용하여 데이터를 정리 및 재구성*
	  → 저장된 CSV파일을 로드하고 정리한 다음, 데이터 형태를 변경하고 새 버전으로 CSV 데이터를 저장한다.
	- *결과 데이터를 데이터 웨어하우스에 로드*
	  → 이전 단계에서 생성된 CSV를 데이터 웨어하우스로 로드하기 위해 SQL에서 COPY 명령어를 실행한다.

- 오케스트레이션 플랫폼은 각 작업을 실행하지만, 작업의 내용은 데이터 인프라 전반에 걸쳐서 서로 다른 시스템에서 실행되는 SQL 및 파이썬 코드로 존재하게 됨

# 데이터 인프라 커스터마이징

- 조직의 문화와 리소스에 따라 데이터 인프라를 1) 자체적으로 구축 하거나, 2) SaaS 공급 업체를 통해 구매하게 됨
- 대부분은 특정 요구사항을 충족하는 도구와 공급업체를 선택하고 나머지는 자체적으로 구축함
- 제약조건과 그에 따른 트레이드오프를 이해하는 것이 중요
	- 제약조건 : 비용, 엔지니어링 리소스, 보안 및 법적 리스크 허용 범위